"""
Phoenix ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ 24ì‹œê°„ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸

1ë¶„ë§ˆë‹¤ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ì²´í¬í•˜ê³  JSON Lines í˜•ì‹ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.
"""

import psutil
import time
import json
import os
from datetime import datetime


def check_system_health():
    """
    ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬

    Returns:
        dict: ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´
    """
    process_name = "python.exe"
    phoenix_processes = []

    for proc in psutil.process_iter(['pid', 'name', 'memory_info', 'cpu_percent', 'create_time']):
        try:
            if proc.info['name'] == process_name:
                # Phoenix í”„ë¡œì„¸ìŠ¤ì¸ì§€ í™•ì¸ (main.py ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤)
                cmdline = proc.cmdline()
                if any('main.py' in arg for arg in cmdline):
                    phoenix_processes.append({
                        "pid": proc.info['pid'],
                        "memory_mb": round(proc.info['memory_info'].rss / 1024 / 1024, 2),
                        "cpu_percent": proc.info['cpu_percent'],
                        "uptime_hours": round((time.time() - proc.info['create_time']) / 3600, 2)
                    })
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            continue

    if phoenix_processes:
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ê°€ì¥ í° í”„ë¡œì„¸ìŠ¤ ì„ íƒ (Phoenix ë©”ì¸ í”„ë¡œì„¸ìŠ¤)
        main_process = max(phoenix_processes, key=lambda x: x['memory_mb'])

        return {
            "timestamp": datetime.now().isoformat(),
            "status": "running",
            "pid": main_process["pid"],
            "memory_mb": main_process["memory_mb"],
            "cpu_percent": main_process["cpu_percent"],
            "uptime_hours": main_process["uptime_hours"],
            "total_processes": len(phoenix_processes)
        }
    else:
        return {
            "timestamp": datetime.now().isoformat(),
            "status": "not_running",
            "pid": None,
            "memory_mb": 0,
            "cpu_percent": 0,
            "uptime_hours": 0,
            "total_processes": 0
        }


def check_log_files():
    """
    ë¡œê·¸ íŒŒì¼ í¬ê¸° ë° ê°œìˆ˜ í™•ì¸

    Returns:
        dict: ë¡œê·¸ íŒŒì¼ ì •ë³´
    """
    logs_dir = "logs"

    if not os.path.exists(logs_dir):
        return {
            "total_size_mb": 0,
            "file_count": 0,
            "latest_log": None
        }

    total_size = 0
    log_files = []

    for filename in os.listdir(logs_dir):
        if filename.endswith('.log'):
            filepath = os.path.join(logs_dir, filename)
            size = os.path.getsize(filepath)
            total_size += size
            log_files.append({
                "name": filename,
                "size_mb": round(size / 1024 / 1024, 2),
                "modified": datetime.fromtimestamp(os.path.getmtime(filepath)).isoformat()
            })

    latest_log = max(log_files, key=lambda x: x['modified']) if log_files else None

    return {
        "total_size_mb": round(total_size / 1024 / 1024, 2),
        "file_count": len(log_files),
        "latest_log": latest_log['name'] if latest_log else None
    }


def check_excel_file(excel_path="phoenix_grid_template_v3.xlsx"):
    """
    Excel íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ë° í¬ê¸° í™•ì¸

    Returns:
        dict: Excel íŒŒì¼ ì •ë³´
    """
    if os.path.exists(excel_path):
        size = os.path.getsize(excel_path)
        modified = datetime.fromtimestamp(os.path.getmtime(excel_path))

        # ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„ì´ 5ì´ˆ ì´ìƒ ê²½ê³¼í–ˆìœ¼ë©´ ì—…ë°ì´íŠ¸ ì¤‘ì§€ ì˜ì‹¬
        time_since_update = (datetime.now() - modified).total_seconds()
        update_status = "recent" if time_since_update < 10 else "stale"

        return {
            "exists": True,
            "size_mb": round(size / 1024 / 1024, 2),
            "last_modified": modified.isoformat(),
            "seconds_since_update": round(time_since_update, 1),
            "update_status": update_status
        }
    else:
        return {
            "exists": False,
            "size_mb": 0,
            "last_modified": None,
            "seconds_since_update": None,
            "update_status": "missing"
        }


def analyze_health_trend(log_file="monitoring_log.jsonl", window=10):
    """
    ìµœê·¼ Nê°œ ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ë©”ëª¨ë¦¬/CPU ì¶”ì„¸ íŒë‹¨

    Args:
        log_file: ëª¨ë‹ˆí„°ë§ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
        window: ë¶„ì„í•  ìµœê·¼ ê¸°ë¡ ê°œìˆ˜

    Returns:
        dict: ì¶”ì„¸ ë¶„ì„ ê²°ê³¼
    """
    if not os.path.exists(log_file):
        return {
            "memory_trend": "unknown",
            "cpu_trend": "unknown",
            "alert": None
        }

    # ìµœê·¼ Nê°œ ê¸°ë¡ ì½ê¸°
    records = []
    with open(log_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        for line in lines[-window:]:
            try:
                records.append(json.loads(line))
            except json.JSONDecodeError:
                continue

    if len(records) < 2:
        return {
            "memory_trend": "insufficient_data",
            "cpu_trend": "insufficient_data",
            "alert": None
        }

    # ë©”ëª¨ë¦¬ ì¶”ì„¸ ë¶„ì„
    memory_values = [r['memory_mb'] for r in records if r['status'] == 'running']
    if len(memory_values) >= 2:
        memory_increase = memory_values[-1] - memory_values[0]
        memory_increase_rate = memory_increase / (len(memory_values) * 1)  # MB/ë¶„

        if memory_increase_rate > 1.0:  # 1MB/ë¶„ ì´ìƒ ì¦ê°€
            memory_trend = "increasing_fast"
        elif memory_increase_rate > 0.5:
            memory_trend = "increasing"
        elif memory_increase_rate < -0.5:
            memory_trend = "decreasing"
        else:
            memory_trend = "stable"
    else:
        memory_trend = "unknown"

    # CPU ì¶”ì„¸ ë¶„ì„
    cpu_values = [r['cpu_percent'] for r in records if r['status'] == 'running']
    if len(cpu_values) >= 2:
        avg_cpu = sum(cpu_values) / len(cpu_values)

        if avg_cpu > 50:
            cpu_trend = "high"
        elif avg_cpu > 20:
            cpu_trend = "medium"
        else:
            cpu_trend = "low"
    else:
        cpu_trend = "unknown"

    # ì•Œë¦¼ ìƒì„±
    alert = None
    if memory_trend == "increasing_fast":
        alert = "âš ï¸ ë©”ëª¨ë¦¬ ê¸‰ê²©íˆ ì¦ê°€ ì¤‘! ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì˜ì‹¬"
    elif memory_values and memory_values[-1] > 1000:  # 1GB ì´ˆê³¼
        alert = "ğŸ”´ ë©”ëª¨ë¦¬ 1GB ì´ˆê³¼! ì¦‰ì‹œ í™•ì¸ í•„ìš”"
    elif cpu_trend == "high":
        alert = "âš ï¸ CPU ì‚¬ìš©ë¥  ë†’ìŒ! ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥ì„±"

    return {
        "memory_trend": memory_trend,
        "cpu_trend": cpu_trend,
        "avg_memory_mb": round(sum(memory_values) / len(memory_values), 2) if memory_values else 0,
        "avg_cpu_percent": round(sum(cpu_values) / len(cpu_values), 2) if cpu_values else 0,
        "alert": alert
    }


def main():
    """
    ë©”ì¸ ëª¨ë‹ˆí„°ë§ ë£¨í”„
    """
    log_file = "monitoring_log.jsonl"
    print(f"Phoenix 24ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    print(f"ë¡œê·¸ íŒŒì¼: {log_file}")
    print(f"Ctrl+Cë¡œ ì¢…ë£Œ\n")

    iteration = 0

    try:
        while True:
            iteration += 1

            # ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬
            health = check_system_health()
            logs_info = check_log_files()
            excel_info = check_excel_file()

            # ì¶”ì„¸ ë¶„ì„ (10ë¶„ë§ˆë‹¤)
            trend = None
            if iteration % 10 == 0:
                trend = analyze_health_trend(log_file)

            # í†µí•© ì •ë³´
            monitoring_data = {
                "iteration": iteration,
                **health,
                "logs": logs_info,
                "excel": excel_info,
                "trend": trend
            }

            # íŒŒì¼ì— ê¸°ë¡ (JSON Lines í˜•ì‹)
            with open(log_file, "a", encoding='utf-8') as f:
                f.write(json.dumps(monitoring_data, ensure_ascii=False) + "\n")

            # ì½˜ì†” ì¶œë ¥
            status_emoji = "ğŸŸ¢" if health['status'] == 'running' else "ğŸ”´"
            print(f"[{datetime.now().strftime('%H:%M:%S')}] {status_emoji} "
                  f"ë©”ëª¨ë¦¬: {health['memory_mb']:.1f}MB | "
                  f"CPU: {health['cpu_percent']:.1f}% | "
                  f"ê°€ë™: {health['uptime_hours']:.1f}h | "
                  f"ë¡œê·¸: {logs_info['total_size_mb']:.1f}MB | "
                  f"Excel: {excel_info['update_status']}")

            # ì¶”ì„¸ ì•Œë¦¼ ì¶œë ¥
            if trend and trend.get('alert'):
                print(f"  {trend['alert']}")

            # 1ë¶„ ëŒ€ê¸°
            time.sleep(60)

    except KeyboardInterrupt:
        print("\n\nëª¨ë‹ˆí„°ë§ ì¢…ë£Œ")
        print(f"ì´ {iteration}íšŒ ì²´í¬ ì™„ë£Œ")

        # ìµœì¢… í†µê³„ ì¶œë ¥
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                records = [json.loads(line) for line in f if line.strip()]

            running_records = [r for r in records if r['status'] == 'running']

            if running_records:
                max_memory = max(r['memory_mb'] for r in running_records)
                avg_memory = sum(r['memory_mb'] for r in running_records) / len(running_records)
                max_cpu = max(r['cpu_percent'] for r in running_records)
                avg_cpu = sum(r['cpu_percent'] for r in running_records) / len(running_records)

                print(f"\nğŸ“Š ìµœì¢… í†µê³„:")
                print(f"  ë©”ëª¨ë¦¬: í‰ê·  {avg_memory:.1f}MB, ìµœëŒ€ {max_memory:.1f}MB")
                print(f"  CPU: í‰ê·  {avg_cpu:.1f}%, ìµœëŒ€ {max_cpu:.1f}%")
                print(f"  ì´ ê°€ë™ ì‹œê°„: {running_records[-1]['uptime_hours']:.1f}ì‹œê°„")


if __name__ == "__main__":
    main()
